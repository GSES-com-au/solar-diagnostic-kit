{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis\n",
    "\n",
    "This document runs a single site through a performance ratio analsys."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Libraries import\n",
    "# ========================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import pytz\n",
    "import math\n",
    "from zoneinfo import ZoneInfo\n",
    "import datetime\n",
    "import geopy.distance\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = AWS Credentials\n",
    "# ========================================================\n",
    "\n",
    "PROD_AWS_PROFILE = \"gsesami-prod\"\n",
    "AWS_REGION = \"us-west-2\"\n",
    "\n",
    "prod_session = boto3.session.Session(profile_name=PROD_AWS_PROFILE)\n",
    "\n",
    "prod_client = prod_session.client(\n",
    "    \"timestream-query\", region_name=AWS_REGION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on timestream variable names:\n",
    "\n",
    "Irrad.kWh.m2.Daily = Expected Generation\n",
    "\n",
    "EnergyYield.kWh.Daily = Clear Sky Model\n",
    "\n",
    "Production.kWh.Daily = Measured Generation\n",
    "\n",
    "Performance = Measured / Expected * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Defining the Site ID, and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site ID\n",
    "site_id = '4dddc226-3464-4c95-aded-875e490a2f02'\n",
    "# Time period\n",
    "date_start = '2022-01-01'\n",
    "\n",
    "# Setting date_end to today\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "date_end = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting site_id name:\n",
    "site_id_full = 'SITE|' + str(site_id)\n",
    "# Reading from DynameDB output:\n",
    "# df_names_full = pd.read_csv('./input_data/Site_List_2023-01-24.csv')\n",
    "\n",
    "# Getting site name\n",
    "# site_name = df_names_full.loc[df_names_full['source'] == site_id_full, 'name'].iloc[0]\n",
    "\n",
    "# Checking\n",
    "print(\"This analysis will be performed on the site: \", site_id_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Getting the Clear Sky Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Reading EnergyYield.kWh.Daily from AWS TimeStream\n",
    "# ========================================================\n",
    "\n",
    "# As for now, during testing, we'll keep the test limited to a single location so not to query timestream constantly:\n",
    "\n",
    "def readClear(date_start, date_end, measure_name, site_id):\n",
    "    timeid = []\n",
    "    data_values = []\n",
    "    ##----------------- read the Performance  --------------##\n",
    "    query = \"\"\"SELECT date, max_by(measure_value::double, time) as prod_val\n",
    "                FROM \"GSESTimeseries\".\"GSESTimeseriesTable\"\n",
    "                WHERE measure_name = '\"\"\" + measure_name + \"\"\"'\n",
    "                AND siteId = '\"\"\" + site_id + \"\"\"'\n",
    "                AND date BETWEEN '\"\"\" + date_start + \"\"\"'\n",
    "                AND '\"\"\" + date_end + \"\"\"'\n",
    "                GROUP BY date\n",
    "                ORDER BY date \"\"\"\n",
    "    \n",
    "    client = prod_client\n",
    "    paginator = client.get_paginator(\"query\")\n",
    "    page_iterator = paginator.paginate(QueryString=query,)\n",
    "    i = 1\n",
    "    for page in page_iterator:\n",
    "        # print(page)\n",
    "        try:\n",
    "            timeid_page = [f[0]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            data_values_page = [f[1]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            timeid = timeid + timeid_page\n",
    "            data_values = data_values + data_values_page\n",
    "        except KeyError:\n",
    "            print('Page {%d} has no data available:'%i)\n",
    "        i = i+1\n",
    "    return timeid, data_values\n",
    "\n",
    "measure_name = 'EnergyYield.kWh.Daily'\n",
    "timeid, data_values = readClear(date_start, date_end, measure_name, site_id)\n",
    "\n",
    "# df_production = pd.DataFrame(data_values, index=timeid, columns=measure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As for now, during testing, we'll keep the test limited to a single location so not to query timestream constantly:\n",
    "\n",
    "df_clear = pd.DataFrame(data_values, index=timeid, columns=[measure_name])\n",
    "df_clear['EnergyYield.kWh.Daily'] = df_clear['EnergyYield.kWh.Daily'].astype(float)\n",
    "\n",
    "# As for now, during testing, we'll keep the test limited to a single location so not to query timestream constantly:\n",
    "df_clear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Getting Expected Generation (Irrad.kWh.m2.Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Reading Irrad.kWh.m2.Daily from AWS TimeStream\n",
    "# ========================================================\n",
    "\n",
    "# As for now, during testing, we'll keep the test limited to a single location so not to query timestream constantly:\n",
    "\n",
    "\n",
    "def readExpected(date_start, date_end, measure_name, site_id):\n",
    "    timeid = []\n",
    "    data_values = []\n",
    "    ##----------------- read the Performance  --------------##\n",
    "    query = \"\"\"SELECT date, max_by(measure_value::double, time) as prod_val\n",
    "                FROM \"GSESTimeseries\".\"GSESTimeseriesTable\"\n",
    "                WHERE measure_name = '\"\"\" + measure_name + \"\"\"'\n",
    "                AND siteId = '\"\"\" + site_id + \"\"\"'\n",
    "                AND date BETWEEN '\"\"\" + date_start + \"\"\"'\n",
    "                AND '\"\"\" + date_end + \"\"\"'\n",
    "                GROUP BY date\n",
    "                ORDER BY date \"\"\"\n",
    "    \n",
    "    client = prod_client\n",
    "    paginator = client.get_paginator(\"query\")\n",
    "    page_iterator = paginator.paginate(QueryString=query,)\n",
    "    i = 1\n",
    "    for page in page_iterator:\n",
    "        # print(page)\n",
    "        try:\n",
    "            timeid_page = [f[0]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            data_values_page = [f[1]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            timeid = timeid + timeid_page\n",
    "            data_values = data_values + data_values_page\n",
    "        except KeyError:\n",
    "            print('Page {%d} has no data available:'%i)\n",
    "        i = i+1\n",
    "    return timeid, data_values\n",
    "\n",
    "measure_name = 'Irrad.kWh.m2.Daily'\n",
    "\n",
    "timeid, data_values = readExpected(date_start, date_end, measure_name, site_id)\n",
    "# df_production = pd.DataFrame(data_values, index=timeid, columns=measure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expected = pd.DataFrame(data_values, index=timeid, columns=[measure_name])\n",
    "df_expected['Irrad.kWh.m2.Daily'] = df_expected['Irrad.kWh.m2.Daily'].astype(float)\n",
    "df_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving to CSV\n",
    "# df_expected.to_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_expected_DO.csv')\n",
    "\n",
    "## Reading to CSV\n",
    "#df_expected = pd.read_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_expected_DO.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Comparison on Clear skies x Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_clear.join(df_expected)\n",
    "df_merged['expected_over_clear'] =  (df_merged['Irrad.kWh.m2.Daily'] / df_merged['EnergyYield.kWh.Daily'] * 100).round(0)\n",
    "df_merged['date'] =  df_merged.index\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Merging clear skies and expected\n",
    "# ========================================================\n",
    "\n",
    "def merge_clear_expe(df1, df2):\n",
    "    df_merged = df1.join(df2)\n",
    "    df_merged['expected_over_clear'] =  (df_merged['Irrad.kWh.m2.Daily'] / df_merged['EnergyYield.kWh.Daily'] * 100).round(0)\n",
    "    df_merged['date'] =  df_merged.index\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "# df_merged.to_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_merged_clear_and_expected_DO.csv')\n",
    "\n",
    "# Reading from CSV\n",
    "#df_merged = pd.read_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_merged_clear_and_expected_DO.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting colours for plotting:\n",
    "def colors_from_values(values, palette_name):\n",
    "    # normalize the values to range [0, 1]\n",
    "    normalized = (values - min(values)) / (max(values) - min(values))\n",
    "    # convert to indices\n",
    "    indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Plotting Performance Ratio over time\n",
    "# ========================================================\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "ax1 = sns.set_style(style=None, rc=None )\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(30,10))\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "sns.lineplot(data = df_merged['Irrad.kWh.m2.Daily'], marker='o', sort = False, ax=ax1)\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data = df_merged['EnergyYield.kWh.Daily'], marker='o', sort = False, ax=ax1)\n",
    "ax3 = ax2.twinx()\n",
    "\n",
    "sns.barplot(data = df_merged, x='date', y='expected_over_clear', alpha=0.3, ax=ax3, palette=colors_from_values(df_merged['expected_over_clear'], \"RdYlGn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Checking values above a certain threshold when comparing clear skies and expected\n",
    "# ========================================================\n",
    "\n",
    "# Defining the threshold for low cloudiness:\n",
    "## a.ka.: Whenever a day has more than 80% of measured generation over expected, that's considered a low cloudiness day\n",
    "threshold_low_cloudiness = 80\n",
    "\n",
    "# Applying:\n",
    "df_merged.loc[df_merged['expected_over_clear'] >= threshold_low_cloudiness, 'is_low_clousdiness_day'] = True \n",
    "df_merged.loc[df_merged['expected_over_clear'] < threshold_low_cloudiness, 'is_low_clousdiness_day'] = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Getting measured generation (Production.kWh.Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# = Reading Production.kWh.Daily from AWS TimeStream\n",
    "# ========================================================\n",
    "\n",
    "def readMeasured(date_start, date_end, measure_name, site_id):\n",
    "    timeid = []\n",
    "    data_values = []\n",
    "    ##----------------- read the Performance  --------------##\n",
    "    query = \"\"\"SELECT date, max_by(measure_value::double, time) as prod_val\n",
    "                FROM \"GSESTimeseries\".\"GSESTimeseriesTable\"\n",
    "                WHERE measure_name = '\"\"\" + measure_name + \"\"\"'\n",
    "                AND siteId = '\"\"\" + site_id + \"\"\"'\n",
    "                AND date BETWEEN '\"\"\" + date_start + \"\"\"'\n",
    "                AND '\"\"\" + date_end + \"\"\"'\n",
    "                GROUP BY date\n",
    "                ORDER BY date \"\"\"\n",
    "    \n",
    "    client = prod_client\n",
    "    paginator = client.get_paginator(\"query\")\n",
    "    page_iterator = paginator.paginate(QueryString=query,)\n",
    "    i = 1\n",
    "    for page in page_iterator:\n",
    "        # print(page)\n",
    "        try:\n",
    "            timeid_page = [f[0]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            data_values_page = [f[1]['ScalarValue'] for f in pd.DataFrame(page[\"Rows\"])['Data']]\n",
    "            timeid = timeid + timeid_page\n",
    "            data_values = data_values + data_values_page\n",
    "        except KeyError:\n",
    "            print('Page {%d} has no data available:'%i)\n",
    "        i = i+1\n",
    "    return timeid, data_values\n",
    "\n",
    "measure_name = 'Production.kWh.Daily'\n",
    "\n",
    "timeid, data_values = readMeasured(date_start, date_end, measure_name, site_id)\n",
    "# df_production = pd.DataFrame(data_values, index=timeid, columns=measure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production = pd.DataFrame(data_values, index=timeid, columns=[measure_name])\n",
    "df_production['Production.kWh.Daily'] = df_production['Production.kWh.Daily'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving to CSV\n",
    "# df_production.to_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_production_clear_and_expected_DO.csv')\n",
    "\n",
    "## Reading CSV\n",
    "# df_production = pd.read_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_production_clear_and_expected_DO.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Merging them and getting daily performance (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = df_production.join(df_merged)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "# df_performance.to_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_performance_DO.csv')\n",
    "\n",
    "# Reading CSV\n",
    "# df_performance = pd.read_csv('./input_data/2_Testing_Performance_analysis/Drummoyne Oval/df_performance_DO.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance['Performance.perc.Daily'] = (df_performance['Production.kWh.Daily'] / df_performance['Irrad.kWh.m2.Daily'] * 100).round(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Kicking off outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we can consider kicking off outliers:\n",
    "\n",
    "#df_performance = df_performance[df_performance['Performance.perc.Daily'] < 120]\n",
    "\n",
    "df_performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring the performance variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Currently in diagno, the following is hard-coded:\n",
    "# > 80% performance = Good\n",
    "# < 80% and > 60% = Average\n",
    "# < 60% = Underperforming\n",
    "\n",
    "def performance_check(row):\n",
    "    if row['Performance.perc.Daily'] >= 80:\n",
    "        val = 'ok'\n",
    "    elif row['Performance.perc.Daily'] >=60:\n",
    "        val = 'medium'\n",
    "    else:\n",
    "        val = 'under'\n",
    "    return val\n",
    "\n",
    "def performance_and_LC_check(row):\n",
    "    if row['is_low_clousdiness_day'] == False:\n",
    "        val = 'High Cloudiness'\n",
    "    else:\n",
    "        val = row['performancelabel']\n",
    "    return val\n",
    "\n",
    "df_performance['performancelabel'] = df_performance.apply(performance_check, axis=1)\n",
    "df_performance['performancelabel'] = df_performance.apply(performance_and_LC_check, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to improve plotting:\n",
    "\n",
    "def colors_from_values(values, palette_name):\n",
    "    # normalize the values to range [0, 1]\n",
    "    normalized = (values - min(values)) / (max(values) - min(values))\n",
    "    # convert to indices\n",
    "    indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette ={\"ok\": \"green\", \"medium\": \"yellow\", \"under\": \"red\", \"High Cloudiness\":\"grey\"}\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "\n",
    "ax1 = sns.set_style(style=None, rc=None)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(50,15))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "\n",
    "# Lineplot for Expected\n",
    "sns.lineplot(data = df_performance['Irrad.kWh.m2.Daily'], marker='o', sort = False, ax=ax1, label='Expected', color='green', linewidth=3)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Lineplot for Measured\n",
    "sns.lineplot(data = df_performance['Production.kWh.Daily'], marker='X', sort = False, ax=ax1, label='Measured', color='blue', linewidth=3)\n",
    "\n",
    "# Barplot for performance\n",
    "sns.barplot(data = df_performance, x='date', y='Performance.perc.Daily', hue='performancelabel', palette=palette, alpha=0.8, ax=ax2)\n",
    "\n",
    "fig.suptitle('Performance over time (daily aggregate) for ' + str(site_id_full) + '\\n'+ 'Includes all days' +'\\n' + str(site_id_full))\n",
    "sns.move_legend(ax1, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(ax2, \"upper left\", bbox_to_anchor=(1, 0.8))\n",
    "\n",
    "figname = str(site_id + '.png')\n",
    "fig.savefig('./plots/' + figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette ={\"ok\": \"green\", \"medium\": \"yellow\", \"under\": \"red\", \"High Cloudiness\":\"grey\"}\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "\n",
    "ax1 = sns.set_style(style=None, rc=None)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(50,15))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "\n",
    "#sns.lineplot(data = df_performance['Irrad.kWh.m2.Daily'], marker='o', sort = False, ax=ax1, label='Expected', color='green')\n",
    "\n",
    "#ax2 = ax1.twinx()\n",
    "\n",
    "#sns.lineplot(data = df_performance['Production.kWh.Daily'], marker='X', sort = False, ax=ax1, label='Measured', color='blue')\n",
    "\n",
    "sns.barplot(data = df_performance, x='date', y='Performance.perc.Daily', hue='performancelabel', palette=palette, alpha=0.8, dodge=None)\n",
    "\n",
    "fig.suptitle('Site Name = '+ str(site_id_full) +'\\nSite ID = '+ str(site_id_full) +'\\nPerformance over time (daily aggregate) - All days' + '\\nLow cloudiness threshold = '+ str(threshold_low_cloudiness) + '% [expected/clear_sky]')\n",
    "sns.move_legend(ax1, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(ax2, \"upper left\", bbox_to_anchor=(1, 0.8))\n",
    "\n",
    "figname = str(site_id + '.png')\n",
    "fig.savefig('./plots/ONLY_PERF_' + figname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Working with low cloudiness days"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Getting low cloudiness days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC = df_performance[df_performance['is_low_clousdiness_day'] == True]\n",
    "df_LC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Reading from CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If reading directly from CSV (not querying AWS timestream) start here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "site_to_read_csv = str(site_id) + \"_\" + str(site_name)\n",
    "site_to_read_csv\n",
    "\n",
    "df_LC = pd.read_csv('./input_data/sites_stored_locally/'+ str(site_to_read_csv) +'.csv', index_col=0)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Plotting low cloudiness' days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette ={\"ok\": \"green\", \"medium\": \"yellow\", \"under\": \"red\"}\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "ax1 = sns.set_style(style=None, rc=None )\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(40,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "\n",
    "fig.suptitle('Site Name = '+ str(site_id_full) +'\\nSite ID = '+ str(site_id_full) +'\\nPerformance over time (daily aggregate) - Only low cloudiness days' + '\\nLow cloudiness threshold = '+ str(threshold_low_cloudiness) + '% [expected/clear_sky]')\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=df_LC, \n",
    "    x='date',\n",
    "    y='Performance.perc.Daily',\n",
    "    hue='performancelabel',\n",
    "    palette=palette,\n",
    "    dodge=None\n",
    "    )\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Functions to check underperformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7\n",
    "threshold_performance = -10\n",
    "threshold_underperformance_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_average(df, window_size):\n",
    "    df['SMA'] = df['Performance.perc.Daily'].rolling(window_size).mean()\n",
    "    return df\n",
    "\n",
    "def add_comparative (df):\n",
    "    df['comparative'] = np.nan\n",
    "    for i in range(len(df)):\n",
    "        df['comparative'].iloc[i] = (df['Performance.perc.Daily'].iloc[i] - df['SMA'].iloc[i])\n",
    "    return df\n",
    "\n",
    "def underperformance_check(df, threshold):\n",
    "    df['underperforming'] = np.nan\n",
    "    for i in range(len(df)):\n",
    "        df[\"underperforming\"].iloc[i] = df['comparative'].iloc[i] < threshold\n",
    "    return df\n",
    "\n",
    "def rolling_underperformance(df, days):\n",
    "    df['countUnder'] = np.nan\n",
    "    # Rolling count of underperforming days:\n",
    "    ix = pd.Series(range(df.shape[0])).where((~df['underperforming']).values, np.nan).ffill().values\n",
    "    notna = pd.notna(ix)\n",
    "    df[\"countUnder\"] = df[notna].groupby(ix[notna]).cumcount()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating SMA based on TRUE values of unpderforming\n",
    "def compare_underperfDay_with_SMA_of_under(df):\n",
    "    df['comparative_of_under'] = np.nan\n",
    "    steps_to_shift = 0\n",
    "    for i in range(len(df)):\n",
    "        if df['performancelabel'][i] == 'under':\n",
    "            steps_to_shift = steps_to_shift + 1\n",
    "            df['comparative_of_under'].iloc[i] = (df['Performance.perc.Daily'].iloc[i] - df['SMA'].iloc[i-steps_to_shift])\n",
    "            df['SMA'].iloc[i] = df['SMA'].iloc[i-steps_to_shift]\n",
    "        else:\n",
    "            steps_to_shift = 0\n",
    "            df['comparative_of_under'].iloc[i] = (df['Performance.perc.Daily'].iloc[i] - df['SMA'].iloc[i])\n",
    "    return df\n",
    "\n",
    "def underperformance_check_of_under(df, threshold):\n",
    "    df['underperforming_of_under'] = np.nan\n",
    "    for i in range(len(df)):\n",
    "        df[\"underperforming_of_under\"].iloc[i] = df['comparative_of_under'].iloc[i] < threshold\n",
    "    return df\n",
    "\n",
    "def rolling_underperformance_of_under(df, days):\n",
    "    df['countTrue_of_under'] = np.nan\n",
    "    # Rolling count of underperforming days:\n",
    "    ix = pd.Series(range(df.shape[0])).where((~df['underperforming_of_under']).values, np.nan).ffill().values\n",
    "    notna = pd.notna(ix)\n",
    "    df[\"countTrue_of_under\"] = df[notna].groupby(ix[notna]).cumcount()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistent_fault_check(df, days):\n",
    "    fault_sites = []\n",
    "    if df['countTrue_of_under'].iloc[-1] >= days:\n",
    "        print(\n",
    "            'Persistent fault detected at '\n",
    "            + site_id_full\n",
    "            + '\\nParameters are:' \n",
    "            + '\\nRolling average window = ' \n",
    "            + str(window_size) \n",
    "            + '\\nPerformance threshold = ' \n",
    "            + str(threshold_performance)\n",
    "            )\n",
    "        fault_sites.append(site_id_full)\n",
    "    else:\n",
    "        print(\"No long persistant faults detected\")\n",
    "    return site_id_full\n",
    "\n",
    "def retro_persistent_fault_check(df, days):\n",
    "    fault_sites = []\n",
    "    dates_fault_started = []\n",
    "    fault_details = np.empty\n",
    "    faulty_df = df[df['countTrue_of_under'] >= days]\n",
    "    sudden_unresolved = False\n",
    "    if not faulty_df.empty:\n",
    "        dates_fault_started = faulty_df[faulty_df['countTrue_of_under'] == days]['date']\n",
    "        count_fault = faulty_df.count()[0]\n",
    "        sudden_unresolved = True\n",
    "        print(\n",
    "            'Sudden and unresolved fault detected at '\n",
    "            + site_id_full \n",
    "            +'\\nSiteID: '\n",
    "            + site_id_full\n",
    "            + '\\nDates in which fault started are:' \n",
    "            + dates_fault_started\n",
    "            + '\\n' \n",
    "            + '\\nTotal days of fault = '\n",
    "            +  str(count_fault)\n",
    "            )\n",
    "        # fault_details.append(site_id_full, site_name, sudden_unresolved, count_fault, faulty_df, dates_fault_started)\n",
    "        fault_sites.append(site_id_full)\n",
    "        return site_id_full, site_id_full, sudden_unresolved, count_fault, faulty_df, dates_fault_started\n",
    "    else:\n",
    "        sudden_unresolved = False\n",
    "        print(\"No long persistant faults detected at \" + site_id_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Checking underperformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute analysis:\n",
    "get_rolling_average(df_LC, window_size)\n",
    "add_comparative(df_LC)\n",
    "underperformance_check(df_LC, threshold_performance)\n",
    "rolling_underperformance(df_LC, threshold_underperformance_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on days that underperformed, excluding such days from the rolling average:\n",
    "compare_underperfDay_with_SMA_of_under(df_LC)\n",
    "underperformance_check_of_under(df_LC, threshold_performance)\n",
    "rolling_underperformance_of_under(df_LC, threshold_underperformance_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retroactively check if there was fault:\n",
    "retro_persistent_fault_check(df_LC, threshold_underperformance_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_id_full, site_id_full, sudden_unresolved, count_fault, faulty_df, dates_fault_started = retro_persistent_fault_check(df_LC, threshold_underperformance_days)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To save it:\n",
    "# df_LC.to_csv(str(site_id_full) + str(site_id) + '_dataframe_low_cloudiness.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdcc8738350348f5da3cd958a6f31e3755dac4740b3163f526dc5114836e977f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
